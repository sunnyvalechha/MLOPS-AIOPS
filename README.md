# MLOPS-AIOPS


* AIOPS - Artificial Intelligence for IT operations.
* AIops is an extension to observability
======================Topics:===============================
1. Gen AI
2. Tradional
3. Use cases
4. LLM
5. Prompt engineering
6. AI Landscape

* Even in 90's there were AI exist but there is advancement of Gen AI so we calling the previous AI is Tradional.
* Let's say there is traditional AI model which is used to predict the events in climate application. Ex: weather of Jaipur on 1 Dec 2025. This we will get easily as the AI can predict with the help of old data.
* Gen AI is here to generate data like text, images and videos. Ex: If we ask to generate an image, a lady in saree having ice cream so AI will generate the image with the help of AI models and huge data they have.
* Large language models "LLM" are also part of Gen AI. It generate new texts.
* Gen AI is used for predict future events and patterns related to observability and report back to engineering team.
* Due to the feature of predicting events Gen AI is helping in incident management which human cannot do as human only see present logs but AI can also predict future **AI OPS**.


-- LLM's - Llama is a family of large language models released by Meta AI starting in February 2023. Llama models come in different sizes, ranging from 1 billion to 2 trillion parameters.
* The Llama 4 Models are a collection of pretrained and instruction-tuned mixture-of-experts LLMs offered in two sizes: Llama 4 Scout & Llama 4 Maverick.
* These models are optimized for multimodal understanding, multilingual tasks, coding, tool-calling, and powering agentic systems. The models have a knowledge cutoff of August 2024.
* Llama407B (latest) has a capacity of 407 billions parameters.
* Behind these models there are super computers who have a capacity of parallel computing with 1000's of GPU's and TPU's.

# Prompt Engineering

* Prompt engineering is a medium to communicate with LLM's. The input is provided by the user to get the desired output is called "prompts".
* It also helps us in cost optimization of an organization.
* Zero short prompting - Zero-shot prompting is a method of asking a large language model (LLM) to complete a task using only the prompt's instructions, without providing any specific examples of the desired output
* Few short prompting - Few-shot prompting is a technique where you provide a large language model with a small number of examples in the prompt itself to guide its response for a specific task
* Multi short prompting - Multi-shot prompting is a technique where you provide a language model with multiple examples of input-output pairs to guide its response to a new query
* Chain of thoughts prompting - Chain of thought (CoT) prompting is a technique that guides a large language model (LLM) to solve a complex problem by breaking it down into intermediate reasoning steps

# AI Landscape:

1. AI chatbots - chatgpt, claude, deepseek
2. AI Agents - Github copilot workspace, bolt.new
3. AI Assitants - Github copilot workspace, "Pieces" for Developers, cursor.ai
4. Python programming language - fastAPI, flask, django
